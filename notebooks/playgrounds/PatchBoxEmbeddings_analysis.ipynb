{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d20bf183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/workspace/code/compositional-representation-learning\")\n",
    "\n",
    "import yaml\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pl_modules.PatchBoxEmbeddings import PatchBoxEmbeddings\n",
    "from datasets import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2abe00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchBoxEmbeddings(\n",
       "  (image_encoder): ImageEncoder(\n",
       "    (conv_1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv_2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (maxpool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv_3): Conv2d(8, 12, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv_4): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (maxpool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv_5): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv_6): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (maxpool_3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv_7): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv_8): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (maxpool_4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv_9): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv_10): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (maxpool_5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv_11): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv_12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (maxpool_6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv_13): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "    (conv_14): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=864, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=6, bias=True)\n",
       "    )\n",
       "    (layers): Sequential(\n",
       "      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (3): ReLU()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): ReLU()\n",
       "      (6): Conv2d(8, 12, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (7): ReLU()\n",
       "      (8): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (9): ReLU()\n",
       "      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (11): ReLU()\n",
       "      (12): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (13): ReLU()\n",
       "      (14): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (15): ReLU()\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): ReLU()\n",
       "      (18): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (19): ReLU()\n",
       "      (20): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (21): ReLU()\n",
       "      (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (23): ReLU()\n",
       "      (24): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (25): ReLU()\n",
       "      (26): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "      (27): ReLU()\n",
       "      (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (29): ReLU()\n",
       "      (30): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (31): ReLU()\n",
       "      (32): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (33): ReLU()\n",
       "      (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (35): ReLU()\n",
       "      (36): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (37): ReLU()\n",
       "      (38): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "      (39): Flatten(start_dim=1, end_dim=-1)\n",
       "      (40): Sequential(\n",
       "        (0): Linear(in_features=864, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=6, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (positional_encoder): PositionalEncoder(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (binding_function): BindingFunction(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=12, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (vq): VectorQuantize(\n",
       "    (project_in): Identity()\n",
       "    (project_out): Identity()\n",
       "    (_codebook): EuclideanCodebook()\n",
       "  )\n",
       "  (image_normalizer): Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_filepath = \"/home/ubuntu/workspace/code/compositional-representation-learning/configs/PatchBoxEmbeddings/PatchBoxEmbeddings_exp_2.yaml\"\n",
    "checkpoint_filepath = \"/home/ubuntu/workspace/experiment_root_dir/PatchBoxEmbeddings_exp_2/PatchBoxEmbeddings_exp_2___2025-11-05__15-32-09/checkpoints/model-epoch=099.ckpt\"\n",
    "\n",
    "with open(config_filepath, \"r\") as file_handle:\n",
    "    config = yaml.safe_load(file_handle)\n",
    "\n",
    "model = PatchBoxEmbeddings.load_from_checkpoint(checkpoint_filepath, config=config)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "081d5ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_embeddings(model, datapoint):\n",
    "    \"\"\"\n",
    "    Extracts key quantized embeddings from a single datapoint using the trained model.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = model.device\n",
    "\n",
    "    # 1. Preprocess and \"batchify\" the single datapoint\n",
    "    # The model's forward method expects a batch.\n",
    "    try:\n",
    "        images = datapoint['images'].unsqueeze(0).to(device)\n",
    "        object_masks = datapoint['object_masks'].unsqueeze(0).to(device)\n",
    "    except TypeError:\n",
    "        # Handle cases where datapoint might be a list/tuple\n",
    "        images = datapoint[0].unsqueeze(0).to(device)\n",
    "        object_masks = datapoint[1].unsqueeze(0).to(device)\n",
    "\n",
    "    # --- This logic is extracted directly from your model's forward() method ---\n",
    "\n",
    "    # 2. Get patches and bounding box\n",
    "    batch_image_patches = model.divide_image_into_patches(images) # (1, grid_h, grid_w, C, patch_h, patch_w)\n",
    "    batch_mask_patches = model.divide_image_into_patches(object_masks.unsqueeze(1)) # (1, grid_h, grid_w, 1, patch_h, patch_w)\n",
    "    batch_bounding_boxes = model.compute_bounding_boxes(batch_mask_patches) # (1, 4)\n",
    "\n",
    "    # 3. Extract single-item data (remove batch dim)\n",
    "    image_patches = batch_image_patches[0] # (grid_h, grid_w, C, patch_h, patch_w)\n",
    "    bounding_box = batch_bounding_boxes[0] # (4,)\n",
    "\n",
    "    # 4. Get object-specific patches\n",
    "    object_patches = image_patches[bounding_box[0]:bounding_box[2] + 1, bounding_box[1]:bounding_box[3] + 1]\n",
    "    object_region = model.stitch_object_patches(object_patches)\n",
    "    bbox_grid_h, bbox_grid_w, C, patch_h, patch_w = object_patches.shape\n",
    "    num_patches = bbox_grid_h * bbox_grid_w\n",
    "    object_patches_flattened = object_patches.reshape(num_patches, C, patch_h, patch_w)\n",
    "\n",
    "    # 5. Handle edge case (from your original code)\n",
    "    if num_patches <= 2:\n",
    "        print(f\"Warning: Only {num_patches} object patches found. Skipping this datapoint.\")\n",
    "        return None\n",
    "\n",
    "    # 6. Resize and encode\n",
    "    # Assuming input images for the encoder are 224x224 as in your training code\n",
    "    object_patches_resized = F.interpolate(object_patches_flattened, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "    object_region_resized = F.interpolate(object_region.unsqueeze(0), size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "    encoder_output = model.image_encoder(torch.cat([object_patches_resized, object_region_resized], dim=0))\n",
    "\n",
    "    object_patch_embeddings = encoder_output[:-1]\n",
    "    object_region_embedding = encoder_output[-1].unsqueeze(0)\n",
    "\n",
    "    # 7. Get positional embeddings\n",
    "    object_grid_coords_normalized = model.compute_positional_data(object_patches)\n",
    "    object_positional_embeddings = model.positional_encoder(object_grid_coords_normalized)\n",
    "\n",
    "    # 8. Quantize to get the 4 desired outputs\n",
    "    \n",
    "    # Output 1: Quantized patch representations\n",
    "    quantized_patch_embeddings, _, _ = model.vq(object_patch_embeddings)\n",
    "    \n",
    "    # Output 2: Quantized position representations\n",
    "    quantized_positional_embeddings, _, _ = model.vq(object_positional_embeddings)\n",
    "\n",
    "    # Output 4: The computed object region representation\n",
    "    quantized_object_region_embedding, _, _ = model.vq(object_region_embedding)\n",
    "\n",
    "    # 9. Get \"correct\" parent set intersection\n",
    "    \n",
    "    # Compute all N*N parent embeddings\n",
    "    parent_embeddings, _ = model.compute_parent_embeddings(quantized_patch_embeddings, quantized_positional_embeddings)\n",
    "    \n",
    "    # Get the diagonal (pos_i, patch_i)\n",
    "    correct_parent_set = torch.diagonal(parent_embeddings, 0).permute(1, 0)\n",
    "    \n",
    "    # Output 3: The \"correct\" parent set representation (intersection)\n",
    "    correct_parent_intersection_box = model.compute_overall_intersection_box(correct_parent_set)\n",
    "\n",
    "    # 10. Return the 4 requested items\n",
    "    return {\n",
    "        \"quantized_patch_embeddings\": quantized_patch_embeddings,\n",
    "        \"quantized_positional_embeddings\": quantized_positional_embeddings,\n",
    "        \"correct_parent_intersection_box\": correct_parent_intersection_box,\n",
    "        \"quantized_object_region_embedding\": quantized_object_region_embedding\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8435f61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0303afb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb7ec7ff0e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datapoint = dataset[0]\n",
    "embeddings = get_embeddings(model, datapoint)\n",
    "\n",
    "plt.imshow(datapoint[\"images\"].permute(1, 2, 0).cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02fd131e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231],\n",
       "        [-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[\"quantized_patch_embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f71ea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203],\n",
       "        [-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[\"quantized_positional_embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec31e6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0538, -0.0086, -0.0797,  0.4462,  0.4914,  0.4203]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[\"correct_parent_intersection_box\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "569ff3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0576,  0.0065, -0.0769,  0.4424,  0.5065,  0.4231]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[\"quantized_object_region_embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2cec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_embeddings_dict = {\n",
    "    key: value.cpu().numpy() if isinstance(value, torch.Tensor) else value\n",
    "    for key, value in embeddings.items()\n",
    "}\n",
    "\n",
    "with open(\"/home/ubuntu/workspace/code/compositional-representation-learning/tmp/emb_1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(numpy_embeddings_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde161f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vh-crl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
