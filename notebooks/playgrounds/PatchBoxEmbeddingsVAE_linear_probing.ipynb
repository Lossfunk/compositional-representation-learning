{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00778d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/vh-crl/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda3/envs/vh-crl/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "AllenNLP not available. Registrable won't work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "Train samples: 50000\n",
      "Test samples: 10000\n",
      "Loading model from /home/ubuntu/workspace/experiment_root_dir/PatchBoxEmbeddingsVAE/PatchBoxEmbeddingsVAE_CIFAR10_exp_1/PatchBoxEmbeddingsVAE_CIFAR10_exp_1___2025-11-19__10-16-25/checkpoints/model-epoch=099.ckpt...\n",
      "\n",
      "--- Extracting Features for BOX Model ---\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 30.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Feature Shape: torch.Size([50000, 128])\n",
      "Extracted Label Shape: torch.Size([50000])\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 29.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Feature Shape: torch.Size([10000, 128])\n",
      "Extracted Label Shape: torch.Size([10000])\n",
      "\n",
      "--- Training Probe on BOX Features ---\n",
      "\n",
      "Training Linear Probe (Input Dim: 128)...\n",
      "Epoch 5/100 | Loss: 1.9046 | Test Acc: 33.94%\n",
      "Epoch 10/100 | Loss: 1.8417 | Test Acc: 35.96%\n",
      "Epoch 15/100 | Loss: 1.8232 | Test Acc: 36.24%\n",
      "Epoch 20/100 | Loss: 1.8112 | Test Acc: 36.40%\n",
      "Epoch 25/100 | Loss: 1.8067 | Test Acc: 37.26%\n",
      "Epoch 30/100 | Loss: 1.8026 | Test Acc: 37.94%\n",
      "Epoch 35/100 | Loss: 1.7998 | Test Acc: 36.92%\n",
      "Epoch 40/100 | Loss: 1.7988 | Test Acc: 36.95%\n",
      "Epoch 45/100 | Loss: 1.7973 | Test Acc: 37.26%\n",
      "Epoch 50/100 | Loss: 1.7964 | Test Acc: 37.57%\n",
      "Epoch 55/100 | Loss: 1.7954 | Test Acc: 36.90%\n",
      "Epoch 60/100 | Loss: 1.7939 | Test Acc: 37.03%\n",
      "Epoch 65/100 | Loss: 1.7938 | Test Acc: 37.66%\n",
      "Epoch 70/100 | Loss: 1.7927 | Test Acc: 36.22%\n",
      "Epoch 75/100 | Loss: 1.7928 | Test Acc: 37.78%\n",
      "Epoch 80/100 | Loss: 1.7917 | Test Acc: 37.13%\n",
      "Epoch 85/100 | Loss: 1.7910 | Test Acc: 37.62%\n",
      "Epoch 90/100 | Loss: 1.7905 | Test Acc: 37.56%\n",
      "Epoch 95/100 | Loss: 1.7902 | Test Acc: 37.88%\n",
      "Epoch 100/100 | Loss: 1.7899 | Test Acc: 37.73%\n",
      "Final Box Embedding Accuracy: 38.00%\n",
      "Loading model from /home/ubuntu/workspace/experiment_root_dir/PatchBoxEmbeddingsVAE/PatchBoxEmbeddingsVAE_CIFAR10_vanilla_exp_0/PatchBoxEmbeddingsVAE_CIFAR10_vanilla_exp_0___2025-11-19__11-24-11/checkpoints/model-epoch=099.ckpt...\n",
      "\n",
      "--- Extracting Features for VANILLA Model ---\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 30.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Feature Shape: torch.Size([50000, 128])\n",
      "Extracted Label Shape: torch.Size([50000])\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 28.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Feature Shape: torch.Size([10000, 128])\n",
      "Extracted Label Shape: torch.Size([10000])\n",
      "\n",
      "--- Training Probe on VANILLA Features ---\n",
      "\n",
      "Training Linear Probe (Input Dim: 128)...\n",
      "Epoch 5/100 | Loss: 1.8831 | Test Acc: 36.02%\n",
      "Epoch 10/100 | Loss: 1.8298 | Test Acc: 37.13%\n",
      "Epoch 15/100 | Loss: 1.8118 | Test Acc: 37.38%\n",
      "Epoch 20/100 | Loss: 1.8032 | Test Acc: 37.80%\n",
      "Epoch 25/100 | Loss: 1.7982 | Test Acc: 37.65%\n",
      "Epoch 30/100 | Loss: 1.7951 | Test Acc: 37.85%\n",
      "Epoch 35/100 | Loss: 1.7927 | Test Acc: 37.67%\n",
      "Epoch 40/100 | Loss: 1.7913 | Test Acc: 37.62%\n",
      "Epoch 45/100 | Loss: 1.7898 | Test Acc: 37.63%\n",
      "Epoch 50/100 | Loss: 1.7887 | Test Acc: 37.61%\n",
      "Epoch 55/100 | Loss: 1.7876 | Test Acc: 37.55%\n",
      "Epoch 60/100 | Loss: 1.7869 | Test Acc: 37.77%\n",
      "Epoch 65/100 | Loss: 1.7862 | Test Acc: 37.71%\n",
      "Epoch 70/100 | Loss: 1.7854 | Test Acc: 37.75%\n",
      "Epoch 75/100 | Loss: 1.7850 | Test Acc: 37.68%\n",
      "Epoch 80/100 | Loss: 1.7844 | Test Acc: 37.70%\n",
      "Epoch 85/100 | Loss: 1.7838 | Test Acc: 37.70%\n",
      "Epoch 90/100 | Loss: 1.7833 | Test Acc: 37.70%\n",
      "Epoch 95/100 | Loss: 1.7830 | Test Acc: 37.86%\n",
      "Epoch 100/100 | Loss: 1.7825 | Test Acc: 37.79%\n",
      "Final Vanilla Embedding Accuracy: 37.95%\n",
      "========================================\n",
      "LINEAR PROBING RESULTS (CIFAR10)\n",
      "========================================\n",
      "Model Type           | Test Accuracy  \n",
      "--------------------------------------\n",
      "Box Embeddings       | 38.00%\n",
      "Vanilla VAE          | 37.95%\n",
      "--------------------------------------\n",
      "Delta (Box - Vanilla): +0.05%\n",
      "Box Embeddings learned a better linearly separable representation.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Linear Probing Experiment: Box Embeddings vs Vanilla VAE\n",
    "# \n",
    "# This notebook loads two pre-trained VAE models (one with box-regularization/inclusion losses and one vanilla) and performs a linear probing experiment on CIFAR10.\n",
    "#\n",
    "# **Goal:** Evaluate if the Box Embedding constraints yield more linearly separable representations than a standard VAE.\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- USER SETUP ---\n",
    "# Ensure the project root is in the path so imports work\n",
    "PROJECT_ROOT = \"/home/ubuntu/workspace/code/compositional-representation-learning\"\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Set Data Root for the Dataset class\n",
    "os.environ[\"DATA_ROOT_DIR\"] = \"/home/ubuntu/workspace/data\" # Adjust if your data is elsewhere\n",
    "\n",
    "# Import project modules\n",
    "from pl_modules import PatchBoxEmbeddingsVAE\n",
    "from datasets import get_dataset\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on device: {device}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Configuration and Checkpoints\n",
    "# \n",
    "# We define the configurations directly here (based on your provided files) and point to the specific checkpoints.\n",
    "\n",
    "# %%\n",
    "# --- Experiment 1: Box Embeddings (Inclusion Loss) ---\n",
    "box_checkpoint_path = \"/home/ubuntu/workspace/experiment_root_dir/PatchBoxEmbeddingsVAE/PatchBoxEmbeddingsVAE_CIFAR10_exp_1/PatchBoxEmbeddingsVAE_CIFAR10_exp_1___2025-11-19__10-16-25/checkpoints/model-epoch=099.ckpt\"\n",
    "\n",
    "box_config = {\n",
    "    \"model\": {\n",
    "        \"type\": \"PatchBoxEmbeddingsVAE\",\n",
    "        \"config\": {\n",
    "            \"embed_dim\": 64,\n",
    "            \"hidden_dims\": [32, 64, 128, 256],\n",
    "            \"grid_size\": [4, 4],\n",
    "            \"gumbel_temp\": 1.0,\n",
    "            \"min_side_length\": 0.1,\n",
    "            \"crop_objects\": False,\n",
    "            \"loss_weights\": {\n",
    "                \"reconstruction_loss\": 10.0,\n",
    "                \"inclusion_loss\": 0.5,\n",
    "                \"box_volume_regularization_loss\": 0.0,\n",
    "                \"min_side_regularization_loss\": 0.5,\n",
    "                \"lpips_loss\": 0.0,\n",
    "                \"ssim_loss\": 0.5,\n",
    "                \"full_image_weight\": 10.0\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"train\": {\n",
    "            \"type\": \"CIFAR10Dataset\",\n",
    "            \"config\": {\n",
    "                \"image_size\": [32, 32],\n",
    "                \"train\": True\n",
    "            },\n",
    "            \"dataloader_config\": {\n",
    "                \"batch_size\": 64,\n",
    "                \"shuffle\": True # Shuffle for probe training\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"trainer\": {\n",
    "        \"optimizer\": {\"type\": \"Adam\", \"config\": {\"lr\": 0.0001}}\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Experiment 2: Vanilla VAE ---\n",
    "vanilla_checkpoint_path = \"/home/ubuntu/workspace/experiment_root_dir/PatchBoxEmbeddingsVAE/PatchBoxEmbeddingsVAE_CIFAR10_vanilla_exp_0/PatchBoxEmbeddingsVAE_CIFAR10_vanilla_exp_0___2025-11-19__11-24-11/checkpoints/model-epoch=099.ckpt\"\n",
    "\n",
    "vanilla_config = {\n",
    "    \"model\": {\n",
    "        \"type\": \"PatchBoxEmbeddingsVAE\",\n",
    "        \"config\": {\n",
    "            \"embed_dim\": 64,\n",
    "            \"hidden_dims\": [32, 64, 128, 256],\n",
    "            \"grid_size\": [4, 4],\n",
    "            \"gumbel_temp\": 1.0,\n",
    "            \"min_side_length\": 0.1,\n",
    "            \"crop_objects\": False,\n",
    "            \"loss_weights\": {\n",
    "                \"reconstruction_loss\": 10.0,\n",
    "                \"inclusion_loss\": 0.0, # Zero inclusion\n",
    "                \"box_volume_regularization_loss\": 0.0,\n",
    "                \"min_side_regularization_loss\": 0.0,\n",
    "                \"lpips_loss\": 0.0,\n",
    "                \"ssim_loss\": 0.5,\n",
    "                \"full_image_weight\": 10.0\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"train\": {\n",
    "            \"type\": \"CIFAR10Dataset\",\n",
    "            \"config\": {\n",
    "                \"image_size\": [32, 32],\n",
    "                \"train\": True\n",
    "            },\n",
    "            \"dataloader_config\": {\n",
    "                \"batch_size\": 64,\n",
    "                \"shuffle\": True\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"trainer\": {\n",
    "        \"optimizer\": {\"type\": \"Adam\", \"config\": {\"lr\": 0.0001}}\n",
    "    }\n",
    "}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Helper Functions\n",
    "# \n",
    "# We need functions to:\n",
    "# 1. Load the VAE model.\n",
    "# 2. Extract features (dataset -> frozen VAE -> tensors).\n",
    "# 3. Train the Linear Probe.\n",
    "\n",
    "# %%\n",
    "def load_model(checkpoint_path, config):\n",
    "    print(f\"Loading model from {checkpoint_path}...\")\n",
    "    model = PatchBoxEmbeddingsVAE.load_from_checkpoint(checkpoint_path, config=config)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def extract_features(model, dataloader, include_patch_embeddings=False):\n",
    "    \"\"\"\n",
    "    Passes data through the frozen VAE and extracts the 'z' embedding.\n",
    "    We specifically extract the LAST element of the patch sequence, \n",
    "    which corresponds to the Full Image embedding.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    print(\"Extracting features...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            # Move inputs to device\n",
    "            batch[\"images\"] = batch[\"images\"].to(device)\n",
    "            batch[\"object_masks\"] = batch[\"object_masks\"].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch)\n",
    "            \n",
    "            # Output 'z' shape: (batch_size, num_patches + 1, box_embed_dim)\n",
    "            # Index -1 corresponds to the Full Image embedding\n",
    "            if include_patch_embeddings:\n",
    "                embeddings = outputs[\"z\"].reshape(outputs[\"z\"].shape[0], -1)\n",
    "            else:\n",
    "                embeddings = outputs[\"z\"][:, -1, :]\n",
    "            \n",
    "            features.append(embeddings.cpu())\n",
    "            labels.append(batch[\"metadata\"][\"label\"])\n",
    "            \n",
    "    features = torch.cat(features, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    print(f\"Extracted Feature Shape: {features.shape}\")\n",
    "    print(f\"Extracted Label Shape: {labels.shape}\")\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def train_linear_probe(train_features, train_labels, test_features, test_labels, lr=3e-4, epochs=100):\n",
    "    input_dim = train_features.shape[1]\n",
    "    probe = LinearProbe(input_dim=input_dim).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(probe.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Create simple dataloaders for the features\n",
    "    train_ds = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "    train_dl = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    \n",
    "    test_ds = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "    test_dl = DataLoader(test_ds, batch_size=128, shuffle=False)\n",
    "    \n",
    "    print(f\"\\nTraining Linear Probe (Input Dim: {input_dim})...\")\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        probe.train()\n",
    "        total_loss = 0\n",
    "        for x, y in train_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = probe(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        # Evaluation\n",
    "        probe.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_dl:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits = probe(x)\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        \n",
    "        acc = 100 * correct / total\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss/len(train_dl):.4f} | Test Acc: {acc:.2f}%\")\n",
    "            \n",
    "    return best_acc\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Prepare Datasets\n",
    "# We need both Train (to train the linear probe) and Test (to evaluate it) sets for CIFAR10.\n",
    "\n",
    "# %%\n",
    "# Train Dataset\n",
    "train_dataset = get_dataset(box_config) # Config is same for data in both cases\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "# Test Dataset\n",
    "test_config_dict = box_config.copy()\n",
    "test_config_dict['data']['train']['config']['train'] = False # Switch to test set\n",
    "test_dataset = get_dataset(test_config_dict)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Evaluate Box Embeddings Model\n",
    "# 1. Load Box Model\n",
    "# 2. Extract Features\n",
    "# 3. Train Probe\n",
    "\n",
    "# %%\n",
    "# 1. Load\n",
    "box_model = load_model(box_checkpoint_path, box_config)\n",
    "\n",
    "# 2. Extract\n",
    "print(\"\\n--- Extracting Features for BOX Model ---\")\n",
    "box_train_feats, box_train_labels = extract_features(box_model, train_loader, include_patch_embeddings=True)\n",
    "box_test_feats, box_test_labels = extract_features(box_model, test_loader, include_patch_embeddings=True)\n",
    "\n",
    "# Clear GPU memory of the VAE\n",
    "del box_model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 3. Train Probe\n",
    "print(\"\\n--- Training Probe on BOX Features ---\")\n",
    "box_acc = train_linear_probe(box_train_feats, box_train_labels, box_test_feats, box_test_labels)\n",
    "print(f\"Final Box Embedding Accuracy: {box_acc:.2f}%\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Evaluate Vanilla VAE Model\n",
    "# 1. Load Vanilla Model\n",
    "# 2. Extract Features\n",
    "# 3. Train Probe\n",
    "\n",
    "# %%\n",
    "# 1. Load\n",
    "vanilla_model = load_model(vanilla_checkpoint_path, vanilla_config)\n",
    "\n",
    "# 2. Extract\n",
    "print(\"\\n--- Extracting Features for VANILLA Model ---\")\n",
    "van_train_feats, van_train_labels = extract_features(vanilla_model, train_loader, include_patch_embeddings=True)\n",
    "van_test_feats, van_test_labels = extract_features(vanilla_model, test_loader, include_patch_embeddings=True)\n",
    "\n",
    "# Clear GPU memory\n",
    "del vanilla_model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 3. Train Probe\n",
    "print(\"\\n--- Training Probe on VANILLA Features ---\")\n",
    "van_acc = train_linear_probe(van_train_feats, van_train_labels, van_test_feats, van_test_labels)\n",
    "print(f\"Final Vanilla Embedding Accuracy: {van_acc:.2f}%\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Results Comparison\n",
    "\n",
    "# %%\n",
    "print(\"=\"*40)\n",
    "print(\"LINEAR PROBING RESULTS (CIFAR10)\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'Model Type':<20} | {'Test Accuracy':<15}\")\n",
    "print(\"-\" * 38)\n",
    "print(f\"{'Box Embeddings':<20} | {box_acc:.2f}%\")\n",
    "print(f\"{'Vanilla VAE':<20} | {van_acc:.2f}%\")\n",
    "print(\"-\" * 38)\n",
    "\n",
    "diff = box_acc - van_acc\n",
    "print(f\"Delta (Box - Vanilla): {diff:+.2f}%\")\n",
    "if diff > 0:\n",
    "    print(\"Box Embeddings learned a better linearly separable representation.\")\n",
    "else:\n",
    "    print(\"Vanilla VAE learned a better linearly separable representation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743719c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6e0f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b2b19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vh-crl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
